A supply chain (SC) is a network of entities (such as manufacturers, distributors, transporters, warehouses etc) involved in producing, transporting, storing and distributing goods and services. The primary goals in the design of a supply chain are to minimize risk, maximize net profits and satisfy end-user demands. \cite{chopra2007supply}. Modern supply chains have complex structures, often spanning multiple continents and a large set of interconnected entities with diverse behaviors. 
Simulation plays a key role in the design, analysis and optimization of supply chain systems.  While closed-form analytical models suffice to analyze simple supply chains, the use of detailed simulation models becomes necessary to capture complex behaviors and dependencies between its components with reasonable accuracy. Simulation allows managers to mitigate risks by evaluating what-if scenarios and provides a mechanism to identify bottlenecks and optimize processes for better profits. 
%Most importantly, simulation-based analysis can provide insights into how different factors, such as lead times, demand variability and inventory levels can impact performance and net profit. 
System Dynamics (SD), Discrete-event Simulation (DES), Monte-Carlo Simulation and Hybrid simulation are some approaches used for modeling and studying supply chains. \cite{Mustafee}. 

Simulation-based optimization is often difficult owing to the large number of decision variables, the computational cost of performance estimation using multiple stochastic simulation runs and non-convex, black-box objective functions.  
%To illustrate with an example, suppose a system has 10 design variables whose values we wish to find within a some given range for maximizing a performance metric (say average net profit).  Some of these design variables might be integer/discrete valued and others may be continuous. If we assume each variable can take one out of  just 10 possible values/levels, the design space will still have $10^{10}$ (10 Billion) points  that we need to explore. 
Since the simulation model is stochastic, long-run average performance estimates (such as the average monthly profit) at a single design point can be obtained by averaging the results over multiple simulation runs with distinct randomization seeds. If each simulation run is assumed to take a millisecond, the time required for exhaustively evaluating the entire design space will still be prohibitive. Although there exists no analytical expression for the objective function or its derivatives in such problems (black-box optimization), the objective functions often display low-order trends and can be mimicked by multi-dimensional polynomial surfaces. Meta-model based optimization approaches exploits this aspect.
%
A \textbf{Meta-model} is a function that approximates the detailed simulation model and is computationally less expensive to evaluate \cite{barton2020tutorial}. If $X = (x_1, x_2, \dots, x_n)$ represents a point in the n-dimensional design space, and multiple runs of the the stochastic simulation model estimate some average performance metric $f(X)$, then the meta-model $g(X)$ is an (ideally smooth and significantly faster to evaluate) function which approximates $f$.  It can be constructed by measuring $f$ at only a few  points in the design space and performing some form of interpolation or regression between them. As the number of measurement points increases, the meta-model typically becomes more and more accurate unless it suffers from over-fitting (leading to drastic overshoots or oscillations in the meta-model surface in-between measured points). Continuous gradient-based optimizers can then be applied over the meta-model surface $g$ to quickly identify promising areas in the design space for further exploration.  
% 
Although meta-models can assist in the optimization process, the process of choosing the right meta-model type, the number of data points to build the meta-model and the right optimizer can be non-trivial and can significantly affect the results.  Response Surface Models (RSM), Radial Basis Functions, Kriging (Gaussian Process Regression), and Neural Networks (NN) are some meta-models types that are used in various application domains.   Kriging, also known as Gaussian Process Regression\textbf{ }(GPR) is a spatial correlation meta-model \cite{kleijnen2009kriging,ankenman2008stochastic}. It uses a \textit{kernel function} to represent the  correlation between different input parameter values. Gaussian kernel, Radial Basis Function (RBF), and periodic RBF are some examples of kernel functions used in Kriging). A Neural Network meta-model is built using a neural network architecture (for example, a multi-layer feed-forward network) with the measured points as training data to learn and mimic the input-output relation. It is then used to approximate the performance measures of the system at a given point. The process of selecting the meta-model type, tuning it and selecting the right optimizer for optimizing over for it are nuanced and problem-dependent choices. 
%
While there exist several commercial tools (such as AnyLogic, FLEXSIM, Arena, IBM Supply Chain solutions), there is a dearth of open libraries in popular programming languages for supply chain design and optimization.  General-purpose discrete-event simulation frameworks such as Python's SimPy library \cite{SimPy} can be used for building simulation models of supply chains. However, validation constitutes a significant fraction of model development time. Having an open library of  validated parameterized component models can be very useful in rapid modeling and design space exploration.  In a similar vein, while there exist open, general-purpose optimization packages, an open tool-set specifically designed for design exploration and optimization of supply chains can have wide utility.

This paper presents the design overview and work-in-progress status of \textbf{InventOpt} - a Python-based open library and tool-set  for supply chain and inventory systems simulation and meta-model based optimization.  InventOpt primarily consists of  a library of component models for simulating supply chains. These component models are built using Python's SimPy library, and can be instantiated, configured and connected together to model complex supply chains. In addition, InventOpt includes a GUI-based tool for guided design-space exploration, meta-model tuning and optimization. To make suitable design choices for InventOpt (such as the meta-model type, number of measurement points relative to the size of the design space, and the choice of the optimization algorithm) that are specifically suited for simulation-based optimization of supply chains, we present a detailed case study.  
%
The case study focuses on modeling and simulation-based optimization of inventory threshold levels in a particular supply chain system. The case study illustrates some of the components in InventOpt that are already built and those that can be generalized further, and serves as a validation for the meta-model based approach. Most importantly, in this case study we perform optimizations using a wide set of meta-models and optimizers and compare the solutions to those generated using a more exhaustive search, as a means of arriving at design choices for InventOpt. The observations from the case study lead us to design choices such as the best meta-model type and parameters, the choice of optimizer and the number of simulation runs for a accuracy-versus-computational cost trade-off.
%
The rest of the paper is organized as follows: in Section \ref{sec:relatedwork}, we present a summary of related work and existing tools for supply chain simulation and optimization. We then present an overview of InventOpt and discuss its proposed features and implementation plan in Section \ref{sec:proposedtool}.  Lastly, Section \ref{sec:casestudy} presents the detailed case study and a summary of the observations, insights and conclusions gained from the case study towards the implementation of InventOpt.

