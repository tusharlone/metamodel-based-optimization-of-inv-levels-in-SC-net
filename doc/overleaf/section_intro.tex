A supply chain (SC) is a network of entities (such as manufacturers, distributors, transporters, warehouses etc) involved in producing, transporting, storing and distributing goods and services. The primary goals in the design of a supply chain are to minimize risk, maximise net profits and satisfy end-user demands. \cite{chopra2007supply}. Modern supply chains have complex structures, often spanning multiple continents and a large set of interconnected entities with diverse behaviors. While deterministic analytical models suffice to analyze simple supply chains, the use of detailed simulation models becomes imperative to capture complex behaviors and dependencies between its components with reasonable accuracy. Simulation allows managers to mitigate risks by evaluating what-if scenarios and provides a mechanism to identify bottlenecks and optimize processes for better profits. Most importantly, simulation-based analysis can provide insights into how different factors, such as lead times, demand variability and inventory levels can impact performance and net profit.
System Dynamics (SD), Discrete-event Simulation (DES), Monte-Carlo Simulation and Hybrid simulation are some approaches used for modeling and studying supply chains. \cite{Mustafee}. 
%
While there exist several commercial tools (such as AnyLogic, FLEXSIM, Arena, IBM Supply Chain solutions), there is a dearth of open libraries in popular programming languages for supply chain design and optimization.  General-purpose discrete-event simulation frameworks (such as Python's SimPy library \cite{SimPy} ) can be used for building simulation models of supply chains. However, validation constitutes a significant fraction of model development time. Having an open library of  pre-built, validated parameterized component models can be very useful in rapid modeling and design space exploration.  

In a similar vein, while there exist open, general-purpose libraries for optimization, simulation-based optimization of supply chains is a non-trivial task because of the enormity of the design space and the computational expense of multiple simulation runs. 
%
To illustrate with an example, suppose a system has 10 design variables whose values we wish to find within a some given range for maximising a performance metric (say average net profit).  Some of these design variables might be integer/discrete valued and others may be continuous. If we assume each variable can take one out of  just 10 possible values/levels, the design space will still have $10^{10}$ (10 Billion) points  that we need to explore. Since the simulation model is stochastic, long-run average performance estimates (such as the average monthly profit) at a single design point can be obtained by averaging the results over multiple simulation runs with distinct randomization seeds. If each simulation run is assumed to take a millisecond, the time required for exhaustively evaluating the entire design space will still be prohibitive. Although there exists no analytical expression for the objective function or its derivatives in such problems (black-box optimization), the objective functions often display low-order trends and can be mimicked by multi-dimensional polynomial surfaces. Meta-model based optimization approaches exploits this aspect.

A \textbf{Meta-model} is a function that approximates the detailed simulation model and is computationally less expensive to evaluate \cite{barton2020tutorial}. If $X = (x_1, x_2, \dots, x_n)$ represents a point in the n-dimensional design space, and multiple runs of the the stochastic simulation model estimate some average performance metric $f(X)$, then the meta-model $g(X)$ is an (ideally smooth) function which approximates $f$.  It can be constructed by measuring $f$ at only a few  points in the design space and performing some form of interpolation or regression between them. As the number of measurement points increases, the meta-model typically becomes more and more accurate unless it suffers from over-fitting (leading to drastic overshoots or oscillations in the meta-model surface in-between measured points). The meta-model should ideally be smooth and significantly easier/faster  to evaluate than the detailed simulation-based measurement.  Continuous gradient-based optimizers can then be applied over the meta-model surface $g$ to quickly identify promising areas in the design space for further exploration.  Response Surface Models (RSM), Radial Basis Functions, Kriging (Gaussian Process Regression), and Neural Networks (NN) are some meta-models types that are used in various application domains.  Neural Networks and Kriging are popular and considered to have better accuracy \cite{barkanyi2021modelling}.  \textbf{Kriging}, also known as \textbf{Gaussian Process Regression }(GPR) is a spatial correlation meta-model \cite{kleijnen2009kriging,ankenman2008stochastic}. It uses a \textit{kernel function} to represent the  correlation between different input parameter values. Euclidean distance, Gaussian kernel, Radial Basis Function (RBF), and periodic RBF are some examples of kernel functions used in Kriging. A \textbf{Neural Network} meta-model is built using a neural network architecture (for example, a multi-layer feed-forward network) with the measured points as training data to learn and mimic the input-output relation. It is then used to approximate the performance measures of the system at a given point. The process of selecting the meta-model type, tuning it and selecting the right optimizer for optimizing over for it are nuanced and problem-dependent choices. 

This paper presents an overview of \textbf{InventOpt} - a Python-based open library and tool-set we propose to build for supply chain and inventory systems simulation and meta-model based optimization. InventOpt primarily consists of  a library of component models for simulating supply chains. These component models are built using Python's SimPy library, and can be instantiated, configured and connected together to model complex supply chains. In addition, InventOpt will include a GUI-based tool for guided design-space exploration, meta-model tuning and optimization. To make suitable design choices for InventOpt (such as the meta-model type, number of measurement points relative to the size of the design space, and the choice of the optimization algorithm) that are specifically suited for simulation-based optimization of supply chains, we perform a detailed case study.  In this case study we consider the problem of optimizing the net average profit in a particular supply chain with a large number of design parameters that control the inventory thresholds and reorder points at various nodes.  We build a modular simulation model and perform computational cost versus accuracy trade-off analysis to determine the number of simulation runs suitable for evaluating each point in the design space.  We then perform detailed simulation-based evaluation at points in the 8-dimensional design space along a regular grid pattern to identify the optimum points/regions with respect to a single objective function. This data serves as a reference for evaluating the meta-model based approach. We separate the measured points into a training set and a test set. Training sets containing various fractions of the total measured points are used to build two kinds of meta-models: NN and GPR. We then perform meta-model based optimization using multiple local optimization algorithms with random restarts and present our observations and insights regarding the impact of these design choices on the quality of the results and the computational effort. We use open Python libraries at each step of the process (namely, SimPy \cite{SimPy} for discrete-event simulation, SciPy.Optimize \cite{2020SciPy-NMeth} for optimization, and the Scikit library for building the meta-models). This case study serves as a basis for generalization into a tool-set for supply chain simulation and optimization. 

The rest of the paper is organized as follows: in Section \ref{sec:relatedwork}, we present a summary of related work and existing tools for supply chain simulation and optimization. We then present an overview of InventOpt and discuss its proposed features and implementation plan in Section \ref{sec:proposedtool}.  Section \ref{sec:casestudy} presents the detailed case study and Section \ref{sec:results} summarizes the observations and insights gained from the case study towards the implementation of InventOpt.

%The supply chain optimization is done by building its analytical or simulation model in computer memory and optimizing over different supply chain parameter values (design space). The analytical model helps examine the standard behaviour of the supply chains. The simulation model captures the supply chain's complex, stochastic nature and dynamic behaviour. It can be built using Discrete Event Simulation (DES) libraries like SimPy \cite{SimPy}. SimPy is an open-source Python library to model any systems in computer memory, is generalized to construct a discrete event simulation model of a system and is not specifically targeted to build supply chain networks. 
%OpenBoxes, Zoho, OpenLMIS, and Sonatype, are a few of the many online tools and platforms available for the supply chain management. These have free and paid features and services. Their products and software tools focus more on managing the supply chain than optimizing it. Section \ref{sec:relatedwork} presents a comprehensive overview of platforms and tools that offer services for modeling and analyzing supply chains. 
%anyLogistix (anyLogic), Simio, and Supply Chain Guru are commercial tools to simulate supply chains that provide various analysis tools, such as optimization and statistical analysis. Still, these are paid tools and cannot be accessed for free. \textit{supplychainpy} is an open-source Python library for simulating and analyzing supply chain systems and inventories with Monte Carlo simulation. However, users need Python programming knowledge to invoke and implement a simulation model for the supply chain and analyze it. We propose to build a framework consisting open-source Python library built on top of SimPy and a GUI-based tool that aids the user in the complete process of supply chain creation to optimization. A user can directly import and instantiate the proposed library to model various supply chain networks with different behaviours and parameters. 
%After building a simulation model for a supply chain network, validation and performance analysis of the model in terms of time complexity and correctness are crucial since the simulation model often inherits the supply chain complexity.
%The validation and performance analysis of a simulation model for a supply chain network is crucial, given that the model typically inherits the complexity of the supply chain. This is particularly true in terms of time complexity and correctness. Due to the potentially vast design space and the need for multiple simulation runs to estimate expected performance measures in a stochastic model, the optimization task is computationally demanding. For example, with ten design variables and just two choices for each parameter value, $2^{10} = 1024$ different design points exist. So the design space is vast, and each simulation run can be computationally costly.
%Furthermore, the optimizers call upon objective functions that require running the simulation model for different parameter values. The optimizer invokes the objective function with continuous parameter values, and the simulation model often has mixed discrete and continuous parameter values. Therefore, most continuous optimizers do not work well for simulation model optimization.
%Moreover, the gradient information is not readily available when optimizing a simulation model. One solution is to use Meta-models. These models are typically used to approximate the relationships between inputs parameters and outputs (performance measures) of the simulation model in a computationally efficient manner. There exists a correlation between the input parameters and output performance measures of the simulation model, and they display discernible patterns. Therefore a Meta-model can exploit its gradient information for the optimizers to work well. We introduce the meta-models utilized in the case-study.
%Meta-models are built on top of the simulation model, and they are less accurate and more time efficient than the simulation model. It is built by sampling a few points from the simulation model design space called training points. It then approximates a continuous surface to training points by exploiting the input-output relationship. The Meta-model $g$ is then used to estimate the performance measure for any input parameter values in the design space instead of the computationally expensive simulation model $f$. 

%This study aims to develop a framework comprising libraries and graphical user interface (GUI) tools that enable the user to model a supply chain network with a visual interface in performing meta-model-based optimization. Several critical tasks must be performed during the meta-model-based optimization process, including selecting an appropriate meta-model, determining the required number of training points, selecting an appropriate sampling method, estimating the necessary number of simulations, and determining the optimal duration of the simulation. Often, these design decisions are not straightforward to follow during the Meta-model based supply chain optimization. The proposed tools will aid the user at each step of these decisions.

%This paper presents a case study that illustrates the individual components and steps of the proposed framework that can aid in making significant decisions about meta-model-based optimization. The case study comprises an inventory optimization problem in the supply chain network. It is modeled, simulated and optimized using the meta-model-based approach, and obtained results and insights are presented. The rest of the paper is organized as follows: in section \ref{sec:relatedwork}, we discuss related work to ours. The proposed framework and GUI-based tool InventOpt is introduced in section \ref{sec:proposedtool}. The section \ref{sec:casestudy} discusses the case study and illustrates the flow of the components in the proposed tool. Finally, section \ref{sec:results} discusses the results and insights obtained from the experiment and concludes the paper.


